"""Unified Ontology Service facade for the Feature Ontology Service.

Implements Task 2.1.6 of PRD-RPG-P2-001: provides a single entry point
that orchestrates all ontology subsystems â€“ store, embeddings, extension,
LLM backend, and seed data generation.

Commands exposed by the facade:
- **build**: Generate seed ontology from scrapers, embed, and store
- **search**: Semantic search across the stored ontology
- **stats**: Aggregate statistics about the ontology
- **extend**: Add custom features from CSV or FeatureNode lists
- **export**: Export ontology to CSV format

Example::

    service = OntologyService.create(project_dir=Path("/my/project"))
    service.build()
    results = service.search("user authentication", top_k=5)
    for path in results:
        print(f"{path.leaf.name}: {path.score:.3f}")
"""

from __future__ import annotations

import logging
from pathlib import Path
from typing import Any, Optional

from pydantic import BaseModel, ConfigDict, Field

from zerorepo.ontology.backend import OntologyBackend
from zerorepo.ontology.chromadb_store import OntologyChromaStore, OntologyStoreConfig
from zerorepo.ontology.embeddings import (
    EmbedderConfig,
    EmbeddingResult,
    FeatureEmbedder,
)
from zerorepo.ontology.extension import (
    ConflictResolution,
    ExtensionResult,
    OntologyExtensionAPI,
)
from zerorepo.ontology.models import FeatureNode, FeaturePath, OntologyStats
from zerorepo.ontology.scrapers.build_ontology import OntologyBuilder

logger = logging.getLogger(__name__)


# ---------------------------------------------------------------------------
# Service configuration
# ---------------------------------------------------------------------------


class OntologyServiceConfig(BaseModel):
    """Configuration for the OntologyService facade."""

    model_config = ConfigDict(frozen=False, validate_assignment=True)

    store_config: OntologyStoreConfig = Field(
        default_factory=OntologyStoreConfig,
        description="Configuration for the ChromaDB-backed store",
    )
    embedder_config: EmbedderConfig = Field(
        default_factory=EmbedderConfig,
        description="Configuration for the embedding pipeline",
    )
    include_github: bool = Field(
        default=True,
        description="Include GitHub Topics seed generator in build",
    )
    include_stackoverflow: bool = Field(
        default=True,
        description="Include StackOverflow Tags seed generator in build",
    )
    include_libraries: bool = Field(
        default=True,
        description="Include Library Docs seed generator in build",
    )
    include_expander: bool = Field(
        default=True,
        description="Include combinatorial taxonomy expander in build",
    )
    expander_target_count: int = Field(
        default=50000,
        ge=100,
        description="Target node count for the taxonomy expander",
    )
    auto_embed_on_build: bool = Field(
        default=True,
        description="Automatically embed nodes after building seed ontology",
    )
    auto_store_on_build: bool = Field(
        default=True,
        description="Automatically store embedded nodes in ChromaDB after build",
    )


# ---------------------------------------------------------------------------
# Build result
# ---------------------------------------------------------------------------


class BuildResult(BaseModel):
    """Result of the ontology build operation."""

    model_config = ConfigDict(frozen=True)

    total_nodes: int = Field(
        ..., ge=0, description="Total number of nodes generated by scrapers"
    )
    stored_count: int = Field(
        ..., ge=0, description="Number of nodes stored in ChromaDB"
    )
    embedding_result: Optional[EmbeddingResult] = Field(
        default=None,
        description="Result of the embedding step (None if embedding skipped)",
    )
    depth_stats: dict[int, int] = Field(
        default_factory=dict,
        description="Node count per hierarchical level",
    )
    source_stats: dict[str, int] = Field(
        default_factory=dict,
        description="Node count per seed generator source",
    )
    max_depth: int = Field(
        default=0, ge=0, description="Maximum hierarchical depth"
    )

    def __repr__(self) -> str:
        return (
            f"BuildResult(total_nodes={self.total_nodes}, "
            f"stored={self.stored_count}, "
            f"max_depth={self.max_depth})"
        )


# ---------------------------------------------------------------------------
# Search result (enriched)
# ---------------------------------------------------------------------------


class SearchResult(BaseModel):
    """Enriched search result wrapping FeaturePath with additional context."""

    model_config = ConfigDict(frozen=True)

    paths: list[FeaturePath] = Field(
        default_factory=list,
        description="Ranked search results",
    )
    query: str = Field(
        ..., description="The original search query"
    )
    total_results: int = Field(
        ..., ge=0, description="Number of results returned"
    )

    @property
    def top_result(self) -> Optional[FeaturePath]:
        """Return the highest-scoring result, or None if empty."""
        return self.paths[0] if self.paths else None

    def __repr__(self) -> str:
        return (
            f"SearchResult(query='{self.query}', "
            f"total_results={self.total_results})"
        )


# ---------------------------------------------------------------------------
# Service errors
# ---------------------------------------------------------------------------


class OntologyServiceError(Exception):
    """Base exception for OntologyService errors."""


class ServiceNotInitializedError(OntologyServiceError):
    """Raised when the service is used before initialization."""


class BuildError(OntologyServiceError):
    """Raised when the ontology build process fails."""


class SearchError(OntologyServiceError):
    """Raised when a search operation fails."""


# ---------------------------------------------------------------------------
# OntologyService Facade
# ---------------------------------------------------------------------------


class OntologyService:
    """Unified facade for the Feature Ontology Service.

    Orchestrates all ontology subsystems through a single, cohesive API:

    - **build()**: Generate seed ontology from scrapers, embed, and store
    - **search()**: Semantic search across the stored ontology
    - **stats()**: Aggregate statistics
    - **extend()**: Add custom features from CSV or node lists
    - **export_csv()**: Export to CSV format

    Example::

        service = OntologyService.create(project_dir=Path("/my/project"))

        # Build the ontology from seed generators
        build_result = service.build()
        print(f"Built {build_result.total_nodes} nodes")

        # Search
        results = service.search("authentication", top_k=5)
        for path in results.paths:
            print(f"  {path.leaf.name}: {path.score:.3f}")

        # Export
        csv_content = service.export_csv(Path("ontology.csv"))

        # Stats
        stats = service.stats()
        print(f"Total nodes: {stats.total_nodes}")
    """

    def __init__(
        self,
        store: OntologyChromaStore,
        embedder: Optional[FeatureEmbedder] = None,
        extension_api: Optional[OntologyExtensionAPI] = None,
        config: Optional[OntologyServiceConfig] = None,
    ) -> None:
        """Initialize the OntologyService.

        Prefer using :meth:`create` for a fully configured instance.

        Args:
            store: The ChromaDB-backed ontology store (must be initialized).
            embedder: Optional embedding pipeline for node vectorization.
            extension_api: Optional extension API for CSV import/merge.
            config: Optional service configuration.
        """
        self._store = store
        self._embedder = embedder
        self._extension_api = extension_api or (
            OntologyExtensionAPI(store=store, embedder=embedder)
            if store is not None
            else None
        )
        self._config = config or OntologyServiceConfig()
        self._built = False
        self._last_builder: Optional[OntologyBuilder] = None

    # ------------------------------------------------------------------
    # Factory
    # ------------------------------------------------------------------

    @classmethod
    def create(
        cls,
        project_dir: Path,
        config: Optional[OntologyServiceConfig] = None,
    ) -> OntologyService:
        """Create a fully configured OntologyService instance.

        Initializes the ChromaDB store, embedding pipeline, and extension
        API in a single call.

        Args:
            project_dir: Project root directory. ChromaDB data is stored
                under ``{project_dir}/.zerorepo/ontology_chroma``.
            config: Optional service configuration.

        Returns:
            A ready-to-use :class:`OntologyService` instance.

        Raises:
            OntologyServiceError: If initialization fails.
        """
        cfg = config or OntologyServiceConfig()

        try:
            # Initialize ChromaDB store
            store = OntologyChromaStore(config=cfg.store_config)
            store.initialize(project_dir, embedding_model=cfg.embedder_config.model_name)

            # Initialize embedder
            embedder = FeatureEmbedder(config=cfg.embedder_config)

            # Initialize extension API
            extension_api = OntologyExtensionAPI(store=store, embedder=embedder)

            service = cls(
                store=store,
                embedder=embedder,
                extension_api=extension_api,
                config=cfg,
            )

            logger.info(
                "OntologyService created for project at %s", project_dir
            )
            return service

        except Exception as exc:
            raise OntologyServiceError(
                f"Failed to create OntologyService: {exc}"
            ) from exc

    # ------------------------------------------------------------------
    # Properties
    # ------------------------------------------------------------------

    @property
    def store(self) -> OntologyChromaStore:
        """Return the underlying ChromaDB store."""
        return self._store

    @property
    def embedder(self) -> Optional[FeatureEmbedder]:
        """Return the embedding pipeline, if configured."""
        return self._embedder

    @property
    def extension_api(self) -> Optional[OntologyExtensionAPI]:
        """Return the extension API, if configured."""
        return self._extension_api

    @property
    def config(self) -> OntologyServiceConfig:
        """Return the service configuration."""
        return self._config

    @property
    def is_built(self) -> bool:
        """Whether the ontology has been built in this session."""
        return self._built

    @property
    def last_builder(self) -> Optional[OntologyBuilder]:
        """Return the last OntologyBuilder used, if any."""
        return self._last_builder

    # ------------------------------------------------------------------
    # Command: build
    # ------------------------------------------------------------------

    def build(
        self,
        include_github: Optional[bool] = None,
        include_stackoverflow: Optional[bool] = None,
        include_libraries: Optional[bool] = None,
        include_expander: Optional[bool] = None,
        target_count: Optional[int] = None,
    ) -> BuildResult:
        """Build the seed ontology from registered generators.

        Runs all configured seed generators (GitHub Topics, StackOverflow
        Tags, Library Docs, Taxonomy Expander), deduplicates nodes,
        validates the hierarchy, optionally embeds and stores them.

        Args:
            include_github: Override config's include_github setting.
            include_stackoverflow: Override config's include_stackoverflow setting.
            include_libraries: Override config's include_libraries setting.
            include_expander: Override config's include_expander setting.
            target_count: Override config's expander_target_count setting.

        Returns:
            A :class:`BuildResult` with build statistics.

        Raises:
            BuildError: If the build process fails.
        """
        cfg = self._config
        gh = include_github if include_github is not None else cfg.include_github
        so = include_stackoverflow if include_stackoverflow is not None else cfg.include_stackoverflow
        lib = include_libraries if include_libraries is not None else cfg.include_libraries
        exp = include_expander if include_expander is not None else cfg.include_expander
        target = target_count if target_count is not None else cfg.expander_target_count

        try:
            # Import generators lazily to avoid import overhead
            from zerorepo.ontology.scrapers.build_ontology import build_ontology

            logger.info("Starting ontology build...")
            builder = build_ontology(
                output_path=None,
                include_github=gh,
                include_stackoverflow=so,
                include_libraries=lib,
                include_expander=exp,
                target_count=target,
            )
            self._last_builder = builder

            nodes = builder.nodes
            total_nodes = len(nodes)
            depth_stats = builder.get_depth_stats()
            source_stats = builder.get_source_stats()
            max_depth = builder.get_max_depth()

            logger.info("Build produced %d nodes", total_nodes)

            # Embed nodes
            embedding_result: Optional[EmbeddingResult] = None
            if cfg.auto_embed_on_build and self._embedder is not None:
                logger.info("Embedding %d nodes...", total_nodes)
                embedding_result = self._embedder.embed_nodes(nodes)
                logger.info("Embedding complete: %s", embedding_result)

            # Store nodes in ChromaDB
            stored_count = 0
            if cfg.auto_store_on_build and self._store.is_initialized:
                logger.info("Storing %d nodes in ChromaDB...", total_nodes)
                stored_count = self._store.add_nodes_batch(
                    nodes, embed=not cfg.auto_embed_on_build
                )
                logger.info("Stored %d nodes", stored_count)

            self._built = True

            result = BuildResult(
                total_nodes=total_nodes,
                stored_count=stored_count,
                embedding_result=embedding_result,
                depth_stats=depth_stats,
                source_stats=source_stats,
                max_depth=max_depth,
            )

            logger.info("Ontology build complete: %s", result)
            return result

        except Exception as exc:
            raise BuildError(f"Ontology build failed: {exc}") from exc

    # ------------------------------------------------------------------
    # Command: search
    # ------------------------------------------------------------------

    def search(
        self,
        query: str,
        top_k: int = 10,
        level: Optional[int] = None,
        parent_id: Optional[str] = None,
        tags: Optional[list[str]] = None,
    ) -> SearchResult:
        """Search the ontology for features matching a query.

        Performs semantic search using vector similarity in the ChromaDB
        store. Optionally filters by level, parent, or tags.

        Args:
            query: Natural language search query.
            top_k: Maximum number of results. Defaults to 10.
            level: Optional filter by hierarchical level.
            parent_id: Optional filter by parent node ID.
            tags: Optional filter by tags (any match).

        Returns:
            A :class:`SearchResult` with ranked paths and scores.

        Raises:
            SearchError: If the search fails.
            ValueError: If query is empty or top_k is not positive.
        """
        if not query or not query.strip():
            raise ValueError("query must not be empty")
        if top_k <= 0:
            raise ValueError("top_k must be positive")

        try:
            has_filters = any(x is not None for x in [level, parent_id, tags])

            if has_filters:
                paths = self._store.search_with_filters(
                    query=query,
                    top_k=top_k,
                    level=level,
                    parent_id=parent_id,
                    tags=tags,
                )
            else:
                paths = self._store.search(query=query, top_k=top_k)

            result = SearchResult(
                paths=paths,
                query=query.strip(),
                total_results=len(paths),
            )

            logger.debug(
                "Search for '%s': %d results", query, result.total_results
            )
            return result

        except ValueError:
            raise
        except Exception as exc:
            raise SearchError(f"Search failed for '{query}': {exc}") from exc

    # ------------------------------------------------------------------
    # Command: stats
    # ------------------------------------------------------------------

    def stats(self) -> OntologyStats:
        """Get aggregate ontology statistics.

        Returns:
            An :class:`OntologyStats` instance with summary metrics.

        Raises:
            OntologyServiceError: If statistics computation fails.
        """
        try:
            return self._store.get_statistics()
        except Exception as exc:
            raise OntologyServiceError(
                f"Failed to compute statistics: {exc}"
            ) from exc

    # ------------------------------------------------------------------
    # Command: extend
    # ------------------------------------------------------------------

    def extend(
        self,
        nodes: Optional[list[FeatureNode]] = None,
        csv_path: Optional[Path] = None,
        csv_content: Optional[str] = None,
        conflict_resolution: ConflictResolution | str = ConflictResolution.OVERRIDE,
        embed: bool = True,
    ) -> ExtensionResult:
        """Extend the ontology with custom features.

        Accepts features from one of three sources:
        1. A list of :class:`FeatureNode` objects
        2. A CSV file path
        3. Raw CSV string content

        Exactly one source must be provided.

        Args:
            nodes: List of FeatureNodes to add.
            csv_path: Path to a CSV file.
            csv_content: Raw CSV string content.
            conflict_resolution: How to handle ID conflicts.
            embed: Whether to auto-embed new features.

        Returns:
            An :class:`ExtensionResult` with merge statistics.

        Raises:
            OntologyServiceError: If extension fails.
            ValueError: If no source or multiple sources are provided.
        """
        sources = sum(
            1
            for src in [nodes, csv_path, csv_content]
            if src is not None
        )
        if sources == 0:
            raise ValueError(
                "Must provide one of: nodes, csv_path, or csv_content"
            )
        if sources > 1:
            raise ValueError(
                "Must provide exactly one of: nodes, csv_path, or csv_content"
            )

        if self._extension_api is None:
            raise OntologyServiceError(
                "Extension API is not configured. "
                "Create the service with OntologyService.create() "
                "or provide an extension_api."
            )

        try:
            if nodes is not None:
                return self._extension_api.extend(
                    nodes=nodes,
                    conflict_resolution=conflict_resolution,
                    embed=embed,
                )
            elif csv_path is not None:
                return self._extension_api.extend_from_csv(
                    file_path=csv_path,
                    conflict_resolution=conflict_resolution,
                    embed=embed,
                )
            else:
                return self._extension_api.extend_from_csv_string(
                    csv_content=csv_content,  # type: ignore[arg-type]
                    conflict_resolution=conflict_resolution,
                    embed=embed,
                )
        except ValueError:
            raise
        except Exception as exc:
            raise OntologyServiceError(
                f"Ontology extension failed: {exc}"
            ) from exc

    # ------------------------------------------------------------------
    # Command: export
    # ------------------------------------------------------------------

    def export_csv(
        self,
        output_path: Optional[Path] = None,
    ) -> str:
        """Export the ontology to CSV format.

        Exports all nodes currently in the store's in-memory index.
        If an :class:`OntologyBuilder` was used during :meth:`build`,
        delegates to the builder's export for full fidelity.

        Args:
            output_path: Optional file path to write the CSV.
                If None, returns the CSV string only.

        Returns:
            The CSV content as a string.

        Raises:
            OntologyServiceError: If export fails.
        """
        try:
            # If we have a builder from a recent build, use it for full
            # fidelity export (preserves order, all fields)
            if self._last_builder is not None:
                csv_content = self._last_builder.export_csv(output_path)
                logger.info(
                    "Exported %d nodes via builder",
                    self._last_builder.node_count,
                )
                return csv_content

            # Otherwise export from the store's in-memory index
            return self._export_from_store(output_path)

        except Exception as exc:
            raise OntologyServiceError(
                f"CSV export failed: {exc}"
            ) from exc

    def _export_from_store(self, output_path: Optional[Path] = None) -> str:
        """Export nodes from the store's in-memory index to CSV.

        Args:
            output_path: Optional file path to write the CSV.

        Returns:
            The CSV content as a string.
        """
        import csv
        import io

        nodes = list(self._store._nodes.values())

        output = io.StringIO(newline="")
        writer = csv.DictWriter(
            output,
            fieldnames=["feature_id", "parent_id", "name", "description", "tags", "level"],
            lineterminator="\n",
        )
        writer.writeheader()

        for node in nodes:
            writer.writerow(
                {
                    "feature_id": node.id,
                    "parent_id": node.parent_id or "",
                    "name": node.name,
                    "description": node.description or "",
                    "tags": "|".join(node.tags),
                    "level": node.level,
                }
            )

        csv_content = output.getvalue()

        if output_path is not None:
            output_path.parent.mkdir(parents=True, exist_ok=True)
            output_path.write_text(csv_content, encoding="utf-8")
            logger.info("Exported %d nodes to %s", len(nodes), output_path)

        return csv_content

    # ------------------------------------------------------------------
    # Node access (passthrough)
    # ------------------------------------------------------------------

    def get_node(self, feature_id: str) -> FeatureNode:
        """Retrieve a single feature node by ID.

        Args:
            feature_id: The unique feature ID.

        Returns:
            The :class:`FeatureNode` with the given ID.

        Raises:
            KeyError: If no node with the given ID exists.
            ValueError: If feature_id is empty.
        """
        return self._store.get_node(feature_id)

    def get_children(self, feature_id: str) -> list[FeatureNode]:
        """List direct children of a feature node.

        Args:
            feature_id: The parent node's unique ID.

        Returns:
            List of child :class:`FeatureNode` instances.

        Raises:
            KeyError: If no node with the given ID exists.
            ValueError: If feature_id is empty.
        """
        return self._store.get_children(feature_id)

    def count(self) -> int:
        """Return the number of nodes in the store.

        Returns:
            Number of stored nodes.
        """
        if self._store.is_initialized:
            return self._store.count()
        return 0
